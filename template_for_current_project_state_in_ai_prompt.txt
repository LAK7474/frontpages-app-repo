# ======================================================
# My Project State Template for frontpages-app-repo
# ======================================================
#
# Author: Luke (LAK7474)
# Last Updated: July 2025
#
# This is my project state template. I provide this to AI assistants
# like Gemini or Copilot to give them full context for my requests.
# If manually updating it feels like a whole load of effort, I can
# open GitHub Copilot while in my repo, type
# "Please can you summarise my repo as it stands right now in the following format",
# paste the below, send, and GitHub Copilot will update it, ready to be sent to any
# assistant - ideally Gemini 2.5 Pro.
#
#

# --- PROJECT SUMMARY ---

My Project: frontpages-app-repo
My GitHub URL: https://github.com/LAK7474/frontpages-app-repo
My Live Feed URL: https://lak7474.github.io/frontpages-app-repo/frontpages.json

Status Summary:
*   I have a local Git repository on my computer that is synced with GitHub.
*   I have two main automated workflows:
    1.  A Python script that scrapes a website, generates `rss.xml` and `frontpages.json`, and pushes them to the repo, which publishes them via GitHub Pages. This also uploads images to Firebase Storage.
    2.  A Node.js Cloud Function (`describeimage`) that is automatically deployed to Firebase from the `functions` folder whenever its code changes.
*   My secrets for Firebase and Gemini are stored in GitHub Actions.


# --- FILE STRUCTURE ---

frontpages-app-repo/
├── .github/
│   └── workflows/
│       ├── deploy-functions.yml
│       └── update-feeds-and-upload.yml
│
├── functions/
│   ├── index.js
│   └── package.json
│
├── .firebaserc
├── .gitignore
├── firebase.json
├── README.md
├── frontpages.json
├── generate.py
├── requirements.txt
├── rss.xml
└── upload_news_images_create_documents_fields.py


# ================================================================
# FILE: .github/workflows/update-feeds-and-upload.yml
# ================================================================

name: Update Feeds and Upload Front Pages

on:
  schedule:
    # Update feeds at 21:59, 22:59, 23:59 UK time
    - cron: '59 20,21,22 * * *'
    # Upload at 22:04, 23:04, 00:04 UK time
    - cron: '4 21,22,23 * * *'
  workflow_dispatch:

jobs:
  update_feeds:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event.schedule == '59 20,21,22 * * *'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies for feed update
        run: pip install requests beautifulsoup4
      - name: Run generate.py script to create feeds
        run: python generate.py
      - name: Commit and push updated feeds
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git pull origin main
          git add rss.xml frontpages.json
          git commit -m "Update RSS and JSON feeds" || echo "No changes to commit"
          git push origin main

  upload_frontpages:
    runs-on: ubuntu-latest
    needs: update_feeds
    if: github.event_name == 'workflow_dispatch' || github.event.schedule == '4 21,22,23 * * *'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies for upload
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Set up Firebase credentials
        run: |
          echo '${{ secrets.FIREBASE_SERVICE_ACCOUNT }}' > service-account.json
      - name: Validate Firebase credentials JSON format
        run: python -c "import json; json.load(open('service-account.json'))"
      - name: Run upload script
        run: python upload_news_images_create_documents_fields.py


# ================================================================
# FILE: .github/workflows/deploy-functions.yml
# ================================================================

name: Deploy Firebase Functions

on:
  push:
    branches:
      - main
    paths:
      - 'functions/**'
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      - name: Install function dependencies
        run: npm --prefix functions install
      - name: Install Firebase CLI
        run: npm install -g firebase-tools
      - name: Deploy to Firebase
        run: |
          firebase deploy --only functions --token "${{ secrets.FIREBASE_TOKEN }}"


# ================================================================
# FILE: generate.py
# ================================================================

import requests
from bs4 import BeautifulSoup
from datetime import datetime, timezone
import re
import json

# --- THIS IS YOUR ORIGINAL, UNCHANGED SCRAPING FUNCTION ---
def get_tomorrows_papers_front_pages():
    """Scrape front page images from Tomorrow's Papers Today"""
    url = "https://www.tomorrowspapers.co.uk/"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    }
    
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        html = response.text
        soup = BeautifulSoup(html, "html.parser")
        
        items = []
        images = soup.select("article img")
        
        for img in images:
            src = img.get("src")
            alt = img.get("alt", "")

            if src and alt:
                # Avoid duplicates
                if not any(item[1] == src for item in items):
                    items.append((alt, src))

            if len(items) >= 10:
                break
        
        return items
        
    except requests.RequestException as e:
        print(f"Error fetching page: {e}")
        return []

# --- THIS IS YOUR ORIGINAL, UNCHANGED RSS FUNCTION ---
def generate_rss(items, source_url):
    """Generate RSS feed from front page items"""
    rss_items = ""
    for title, img_url in items:
        title = title.replace("&", "&").replace("<", "<").replace(">", ">")
        
        rss_items += f"""
        <item>
          <title>{title}</title>
          <link>{img_url}</link>
          <description><![CDATA[<img src="{img_url}" alt="{title}" />]]></description>
          <guid>{img_url}</guid>
          <pubDate>{datetime.now(timezone.utc).strftime("%a, %d %b %Y %H:%M:%S +0000")}</pubDate>
        </item>
        """

    rss_feed = f"""<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>UK Newspaper Front Pages - Tomorrow's Papers Today</title>
    <link>{source_url}</link>
    <description>Daily UK newspaper front pages from Tomorrow's Papers Today</description>
    <lastBuildDate>{datetime.now(timezone.utc).strftime("%a, %d %b %Y %H:%M:%S +0000")}</lastBuildDate>
    <language>en-GB</language>
    {rss_items}
  </channel>
</rss>
"""
    return rss_feed

# --- THIS IS THE NEW FUNCTION TO GENERATE JSON ---
def generate_json(items, source_url, rss_feed_url):
    """Generate JSON feed from front page items in the specified format."""
    pub_date_str = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')

    output_dict = {
        "status": "ok",
        "feed": {
            "url": rss_feed_url,
            "title": "UK Newspaper Front Pages - Tomorrow's Papers Today",
            "link": source_url,
            "author": "",
            "description": "Daily UK newspaper front pages from Tomorrow's Papers Today",
            "image": ""
        },
        "items": []
    }

    for title, img_url in items:
        image_html = f'<img src="{img_url}" alt="{title}">'
        
        item_dict = {
            "title": title,
            "pubDate": pub_date_str,
            "link": img_url,
            "guid": img_url,
            "author": "",
            "thumbnail": "",
            "description": image_html,
            "content": image_html,
            "enclosure": {},
            "categories": []
        }
        output_dict["items"].append(item_dict)

    return json.dumps(output_dict, indent=2)

def main():
    """Main function to scrape and generate RSS and JSON"""
    source_url = "https://www.tomorrowspapers.co.uk/"
    # --- UPDATED URL ---
    rss_feed_url = "https://lak7474.github.io/frontpages-app-repo/rss.xml"
    
    print("Scraping front pages from Tomorrow's Papers Today...")
    items = get_tomorrows_papers_front_pages()
    
    if not items:
        print("No front page images found.")
        return
    
    print(f"Found {len(items)} front page images:")
    for title, url in items:
        print(f"  - {title}")
    
    rss_xml = generate_rss(items, source_url)
    with open("rss.xml", "w", encoding="utf-8") as f:
        f.write(rss_xml)
    print("RSS feed generated as 'rss.xml'")

    json_output = generate_json(items, source_url, rss_feed_url)
    with open("frontpages.json", "w", encoding="utf-8") as f:
        f.write(json_output)
    print("JSON feed generated as 'frontpages.json'")

if __name__ == "__main__":
    main()


# ================================================================
# FILE: upload_news_images_create_documents_fields.py
# ================================================================

import os
import requests
import firebase_admin
from firebase_admin import credentials, firestore, storage
from urllib.parse import quote
from PIL import Image
from io import BytesIO

# === CONFIGURATION ===
SERVICE_ACCOUNT_PATH = "service-account.json"
BUCKET_NAME = "frontpages-fireb.appspot.com"
COLLECTION_NAME = "frontpage_fixed"
# --- UPDATED URL ---
RSS_JSON_FEED_URL = "https://lak7474.github.io/frontpages-app-repo/frontpages.json"

# === INITIALIZE FIREBASE ===
if not firebase_admin._apps:
    cred = credentials.Certificate(SERVICE_ACCOUNT_PATH)
    firebase_admin.initialize_app(cred, {
        'storageBucket': BUCKET_NAME
    })

db = firestore.client()
bucket = storage.bucket()

# === DELETE EXISTING DOCUMENTS ===
def delete_all_documents():
    docs = db.collection(COLLECTION_NAME).stream()
    for doc in docs:
        doc.reference.delete()
    print(f"🧹 All documents deleted from {COLLECTION_NAME}")

# === FETCH JSON FEED ===
def fetch_feed():
    resp = requests.get(RSS_JSON_FEED_URL)
    resp.raise_for_status()
    return resp.json().get('items', [])

# === PROCESS EACH ITEM ===
def process_items(items):
    for item in items:
        image_src = item.get('link')
        if not image_src:
            print("▶️  Skipped item with no link")
            continue

        filename = os.path.basename(image_src)
        doc_id = os.path.splitext(filename)[0]

        try:
            r = requests.get(image_src, stream=True)
            r.raise_for_status()
            img_data = r.content
        except Exception as e:
            print(f" ❌ Download failed for {image_src}: {e}")
            continue

        try:
            img = Image.open(BytesIO(img_data))
            width, height = img.size
        except Exception as e:
            print(f" ❌ Could not get image dimensions for {filename}: {e}")
            width, height = None, None

        blob_path = f"images/{filename}"
        blob = bucket.blob(blob_path)
        blob.upload_from_string(img_data, content_type=r.headers.get('Content-Type', 'image/jpeg'))

        encoded_path = quote(blob_path, safe='')
        public_url = f"https://firebasestorage.googleapis.com/v0/b/{BUCKET_NAME}/o/{encoded_path}?alt=media"

        doc_ref = db.collection(COLLECTION_NAME).document(doc_id)
        doc_ref.set({
            'title': item.get('title', ''),
            'pubDate': item.get('pubDate', ''),
            'image': public_url,
            'width': width,
            'height': height,
            'fetched': firestore.SERVER_TIMESTAMP
        })
        print(f" ✅ Uploaded & saved: {doc_id} ({width}x{height})")

def main():
    print("🧹 Clearing Firestore collection…")
    delete_all_documents()

    print("🔄 Fetching feed…")
    items = fetch_feed()
    print(f"   → {len(items)} items found. Processing…")
    process_items(items)
    print("✔️  Done.")

if __name__ == "__main__":
    main()


# ================================================================
# FILE: functions/index.js
# ================================================================

console.log('Starting function initialization');

const { onRequest } = require('firebase-functions/v2/https');
const axios = require('axios');
const cors = require('cors')({ origin: true });

console.log('Modules loaded successfully');

exports.describeimage = onRequest(
  {
    timeoutSeconds: 120,
    memory: '256MB',
    region: 'us-central1',
    invoker: 'public',
    secrets: ["GEMINI_API_KEY"],
  },
  async (req, res) => {
    cors(req, res, async () => {
      console.log('describeimage (onRequest) invoked with body:', JSON.stringify(req.body));
      const imageUrl = req.body.data?.imageUrl;
      if (!imageUrl) {
        console.error('Missing imageUrl in req.body.data');
        res.status(400).send({ error: { message: 'Invalid argument: Missing imageUrl in the request body.' } });
        return;
      }
      try {
        console.log('Fetching image from:', imageUrl);
        const imageResponse = await axios.get(imageUrl, { responseType: 'arraybuffer' });
        console.log('Image fetched, converting to base64');
        const base64Image = Buffer.from(imageResponse.data, 'binary').toString('base64');
        if (!process.env.GEMINI_API_KEY) {
            console.error('GEMINI_API_KEY not found in environment.');
            throw new Error('Server configuration error: API key is missing.');
        }

        console.log('Calling Gemini API with gemini-1.5-flash model and analyst prompt...');
        const geminiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${process.env.GEMINI_API_KEY}`;
        
        const geminiResponse = await axios.post(
          geminiUrl,
          {
            contents: [{
              parts: [
                { text: "Please give a solid analysis of the day's news, based on this newspaper front page. Go through the headlines, the stories, what is says about the current state of politics, the public mood etc. Be creative. Start with \"Today's insert newspaper title here front page...\" - this must be how it starts." },
                { inlineData: { mimeType: 'image/jpeg', data: base64Image } }
              ]
            }]
          },
          { headers: { 'Content-Type': 'application/json' } }
        );

        const analysis = geminiResponse.data?.candidates?.[0]?.content?.parts?.[0]?.text || 'No analysis generated.';
        console.log('SUCCESS! Analysis generated:', analysis);

        res.status(200).send({ data: { analysis } });

      } catch (error) {
        const errorMessage = error.response?.data?.error?.message || error.message;
        console.error('Error inside try-catch block:', errorMessage, error.stack);
        res.status(500).send({ error: { message: `Image captioning failed: ${errorMessage}` } });
      }
    });
  }
);

console.log('Function initialization completed');


# ================================================================
# FILE: functions/package.json
# ================================================================

{
  "name": "skynews-frontpages-functions",
  "description": "Cloud Functions for the newspaper front pages app",
  "main": "index.js",
  "engines": {
    "node": "18"
  },
  "dependencies": {
    "axios": "^1.6.8",
    "cors": "^2.8.5",
    "firebase-functions": "^5.0.1"
  },
  "private": true
}


# ================================================================
# FILE: firebase.json
# ================================================================

{
  "functions": {
    "source": "functions"
  }
}


# ================================================================
# FILE: .firebaserc
# ================================================================

{
  "projects": {
    "default": "frontpages-fireb"
  }
}


# ================================================================
# --- MY REPOSITORY SECRETS ---
# ================================================================
#
# Location: Settings > Secrets and variables > Actions
#
# - FIREBASE_SERVICE_ACCOUNT: The full JSON for the Firebase service account.
# - FIREBASE_TOKEN: The token generated by `firebase login:ci`.
# - GEMINI_API_KEY: The API key for Google Gemini.
#